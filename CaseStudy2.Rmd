---
title: "Case Study 2"
author: "Miguel Bonilla"
date: "4/11/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#load libraries
library(MASS)
library(caret)
library(randomForest)
library(e1071)
library(tidyverse)
library(ggthemes)
library(naivebayes)

```


Load given dataset with information on over 800 employees.
Create categorical variables for finding categorical patterns.
```{r}
csdata <- read.csv('CaseStudy2-data.csv')

csdata1 <- csdata %>% mutate(fAge=cut(Age,
                                     breaks=c(10,20,25,30,40,50,80),
                                     labels=c("18-20", "21-25", "26-30", "31-40","40-50", "50+")),
                             Attrition=as.factor(Attrition),
                             BusinessTravel=as.factor(BusinessTravel),
                             fDailyRate=cut(DailyRate,
                                           DailyRate,
                                           breaks=c(100,200,300,500,750,1000,1250,1500),
                                           labels=c("100-200", "201-300", "301-500", "501-750", "751-1000", "1001-1250", "1251+")),
                             Department=as.factor(Department),
                             fDistanceFromHome=cut(DistanceFromHome,
                                                 breaks=c(0,5,10,15,20,25,30),
                                                 labels=c("<5","6-10","11-15","16-20","21-25","26-30")),
                             Education=as.factor(Education),
                             EducationField=as.factor(EducationField),
                             EnvironmentSatisfaction=as.factor(EnvironmentSatisfaction),
                             Gender=as.factor(Gender),
                             fHourlyRate=cut(HourlyRate,
                                            breaks=c(0,40,50,60,75,90,200),
                                            labels=c("<40","41-50","51-60","61-75","76-90","90+")),
                             JobInvolvement=as.factor(JobInvolvement),
                             JobLevel=as_factor(JobLevel),
                             JobRole=as.factor(JobRole),
                             JobSatisfaction=as.factor(JobSatisfaction),
                             MaritalStatus=as.factor(MaritalStatus),
                             fMonthlyIncome=cut(MonthlyIncome,
                                               breaks=c(0,1000,2000,3000,5000,7500,10000,12500,15000,17500,50000),
                                               labels=c("<1k","1k-2k","2k-3k","3k-5k","5k-7.5k","7.5k-10k","10k-12.5k","12.5k-15k","15k-17.5k",">17.5k")),
                             fMonthlyRate=cut(MonthlyRate,
                                             breaks=c(0,3000,5000,7500,10000,15000,20000,400000),
                                             labels=c("<3k","3k-5k","5k-7.5k","7.5k-10k","10k-15k","15k-20k",">20k")),
                             NumCompaniesWorked=as.factor(NumCompaniesWorked),
                             OverTime=as.factor(OverTime),
                             fPercentSalaryHike=cut(PercentSalaryHike,
                                                   breaks=c(0,10,12,14,16,18,20,22,100),
                                                   labels=c("<10%","10-12%","12-14%","14-16%","16-18%","18-20%","20-22%","<22%")),
                             PerformanceRating=as.factor(PerformanceRating),
                             RelationshipSatisfaction=as.factor(RelationshipSatisfaction),
                             StockOptionLevel=as.factor(StockOptionLevel),
                             fTotalWorkingYears=cut(TotalWorkingYears,
                                                   breaks=c(-1,1,3,5,7,10,15,20,30,60),
                                                   labels=c("0-1","1-3","3-5","5-7","7-10","10-15","15-20","20-30",">30")),
                             TrainingTimesLastYear=as.factor(TrainingTimesLastYear),
                             WorkLifeBalance=as.factor(WorkLifeBalance),
                             fYearsAtCompany=cut(YearsAtCompany,
                                                breaks=c(-1,1,2,3,5,7,10,15,20,60),
                                                labels=c("0-1","1-2","2-3","3-5","5-7","7-10","10-15","15-20",">20")),
                             fYearsInCurrentRole=cut(YearsInCurrentRole,
                                                    breaks=c(-1,1,2,3,5,7,10,15,60),
                                                    labels=c("0-1","1-2","2-3","3-5","5-7","7-10","10-15",">15")),
                             YearsSinceLastPromotion=as.factor(YearsSinceLastPromotion),
                             fYearsWithCurrManager=cut(YearsWithCurrManager,
                                                      breaks=c(-1,1,2,3,5,7,10,14,60),
                                                      labels=c("0-1","1-2","2-3","3-5","5-7","7-10","10-14",">14")))
csdata1 <- csdata1 %>% select(-c(1,10,11,23,28))#drop unusable columns

csdata1 <- csdata1 %>% select(1,3:42,2) #rearrange columns

```

Next, we will determine the top 3 factors by building a NaiveBayes classifier, and finding the importance of each variable in the model.
```{r}
#loop for determining the top 3 factors contributing to attrition
set.seed(461)
df <- data.frame()
for (i in 1:10) {
  train_indx <- sample(1:nrow(csdata1), round(.7*nrow(csdata1)))
  train_exp <- csdata1[train_indx,1:30]
  train_resp <- csdata1[train_indx,42]
  test_nb <- csdata1[-train_indx,]
  
  tgrid <- data.frame("laplace"=1, "usekernel"=FALSE,"adjust"=1)
  modl <- train(train_exp,train_resp,method = "naive_bayes",tuneGrid = tgrid,metric = "Kappa")
  importance <- varImp(modl,scale = FALSE)
  importance <- data.frame("Variable"=rownames(importance$importance),"Importance"=importance$importance[1])
  df <- rbind(df,importance)
}

colnames(df) <- c("Variable","Importance")
rownames(df) <- 1:nrow(df)

df %>% group_by(Variable) %>% summarize(Mean=mean(Importance)) %>% arrange(desc(Mean))
```
The previous table shows that Overtime, Monthly Income, and Total Working year have the most weight in determining employee attrition at the company.

Generate visuals showing the proportional comparison of attrition for each of the top 3 variables.

```{r}
csdata1 %>% ggplot(aes(x=OverTime, fill=Attrition))+geom_bar(position = "fill")+ggtitle("Attrition Rate for Overtime")+ylab("Proportion")+theme_calc()+theme_calc()+scale_fill_brewer()
csdata1 %>% ggplot(aes(x=fMonthlyIncome,fill=Attrition))+geom_bar(position = "fill")+ggtitle("Attrition Rate for Monthly Income Ranges")+ylab("Proportion")+theme_calc()+scale_fill_brewer()
csdata1 %>% ggplot(aes(x=fTotalWorkingYears,fill=Attrition))+geom_bar(position = "fill")+ggtitle("Attrition Rate for Total Working Years Ranges")+ylab("Proportion")+theme_calc()+scale_fill_brewer()

```
Employees with overtime are about 3 times more likely to leave. THere is a downward trend in attrition for employees with higher salaries, with a small reversal for employees making over 7500 a month.

Fit a NaiveBayes model, tuning for the laplace transform to see if we can achieve a minimum .60 in both specificity and sensitivity.

```{r}
#naivebayes
#set.seed(441)
loop_seq <- seq(0,5,.1)
df3 <- data.frame()
for (i in 1:51) {
  df_nb <- data.frame()
  for (j in 1:5) {
  csdata2 <- csdata1 %>% select(Attrition,OverTime,MonthlyIncome,TotalWorkingYears,YearsAtCompany,StockOptionLevel,MaritalStatus,JobLevel,YearsInCurrentRole,YearsWithCurrManager,Age,JobInvolvement,JobRole,JobSatisfaction,Department,DistanceFromHome,EnvironmentSatisfaction,WorkLifeBalance,TrainingTimesLastYear,Education,MonthlyRate,NumCompaniesWorked,DailyRate,RelationshipSatisfaction,HourlyRate,YearsSinceLastPromotion,BusinessTravel,EducationField,PercentSalaryHike)
  train_indx <- sample(1:nrow(csdata2), round(.7*nrow(csdata2)))
  train_nb <- csdata2[train_indx,]
  test_nb <- csdata2[-train_indx,]
  
  model <- naiveBayes(Attrition~.,train_nb,laplace = loop_seq[i])
  predictions <- predict(model,test_nb)
  cm <- confusionMatrix(predictions,test_nb$Attrition)
  df_cm <- data.frame("Accuracy"=cm$overall[1],"Sensitivity"=cm$byClass[1],"Specificity"=cm$byClass[2])
  df_nb <- rbind(df_nb,df_cm)
  }
  df3 <- rbind(df3,data.frame("mean acc"=mean(df_nb$Accuracy),"mean sens"=mean(df_nb$Sensitivity),"mean spec"=mean(df_nb$Specificity),"laplace"=i))
}

```

Curve showing the resulting mean accuracy, sensitivity and specificity for each value of the laplace transform. We can see the models were not able to reach the threshold consistently due to the unbalance in the category being studied (Attrition is 16%, which is significantly smaller than 50%)

```{r}
df3 %>% ggplot(aes(x=laplace))+
  geom_line(aes(y=mean.acc,color="Accuracy"))+
  geom_line(aes(y=mean.spec, color="Specificity"))+
  geom_line(aes(y=mean.sens,color="Sensitivity"))+
  theme_calc()+scale_color_manual(
    values = c("Accuracy"="#074269", "Specificity"="#0EADAB","Sensitivity"="#FA2341"))+
      ggtitle("NaiveBayes Performance")+
      ylab("Rate")+
      xlab("Laplace Transform")
```
We will use a Random Forest model which has better performance with unbalanced data.
We will find a starting value for the mtry parameter using the train function.

```{r}
#randomforest
set.seed(461)
df_data <- csdata1

train_indx <- sample(1:nrow(df_data), round(.7*nrow(df_data)))
train_exp <- df_data[train_indx,1:41]
train_resp <- df_data[train_indx,42]
test_nb <- df_data[-train_indx,]
rf_train <- train(train_exp,train_resp,method = "rf")
varImp(rf_train,scale = FALSE)

```

Fit the model using mtry=16, and adjusting the cutoff values to .68 for no attrition, and .15 for attrition. Create 10 random 70-30 splits to assess model performance.
```{r}
set.seed(1821)
df_data <- csdata1
df_rf <- data.frame()
for (i in 1:10) {
  train_indx <- sample(1:nrow(df_data), round(.7*nrow(df_data)))
  train_rf <- df_data[train_indx,]
  test_nb <- df_data[-train_indx,]
  
  rf <- randomForest(Attrition~.,data = train_rf, mtry=16,ntree=300, cutoff = c(.68,.15))
  rf_predict <- predict(rf,test_nb)
  rf_cm <- confusionMatrix(rf_predict,test_nb$Attrition)
  rf_specs <- data.frame("Accuracy"=rf_cm$overall[1],"Sensitivity"=rf_cm$byClass[1],"Specificity"=rf_cm$byClass[2])
  df_rf <- rbind(df_rf,rf_specs)
}

summary(df_rf)
df_rf <- df_rf %>% mutate("Iteration"=1:nrow(df_rf))

```
Plot the model accuracy, specificity and sensitivity over the 10 iterations.
```{r}
df_rf %>% ggplot(aes(x=Iteration))+
  geom_line(aes(y=Accuracy,color="Accuracy"))+
  geom_line(aes(y=Sensitivity,color="Sensitivity"))+
  geom_line(aes(y=Specificity,color="Specificity"))+
  theme_calc()+scale_color_manual(
    values = c("Accuracy"="#074269", "Specificity"="#0EADAB","Sensitivity"="#FA2341"))+
      ggtitle("Random Forest Performance")+
      ylab("Rate")+
      xlab("Iteration")
```
Use the forward selection automatic method to find ideal variables to include in the model

```{r}
#regression for salary
lm_data <- csdata1 %>% select(-fMonthlyIncome)
lm_all <- lm(MonthlyIncome~.,lm_data)
stepAIC(lm_all,direction = "forward")#find a model
```

Adjust the model from the selection process, adding interactions and creating 10 random 70-30 splits to assess the model's performance.
```{r}

set.seed(766)
lm_df <- data.frame()
for (i in 1:10) {
  #create a 70-30 train-test split each iteration
  lm_indx <- sample(1:nrow(lm_data), round(nrow(lm_data)*.7))
  lm_train <- lm_data[lm_indx,]
  lm_test <- lm_data[-lm_indx,]
  
  lm_modl <- lm(formula = MonthlyIncome ~BusinessTravel + DailyRate + 
                  Department + Education + EducationField + 
                  EnvironmentSatisfaction + Gender + JobInvolvement + 
                  JobLevel + JobRole + JobSatisfaction + MaritalStatus + MonthlyRate + 
                  NumCompaniesWorked + OverTime + PercentSalaryHike + PerformanceRating + 
                  RelationshipSatisfaction + StockOptionLevel + 
                  TrainingTimesLastYear + WorkLifeBalance + YearsAtCompany + 
                  YearsInCurrentRole + YearsSinceLastPromotion + YearsWithCurrManager + 
                  fAge + DailyRate*MaritalStatus + fDistanceFromHome + fHourlyRate + MonthlyRate*Education + 
                  PercentSalaryHike*DailyRate + fTotalWorkingYears + 
                  YearsInCurrentRole*JobInvolvement + YearsWithCurrManager*Education + Attrition, 
                data = lm_data)
  lm_predic <- predict(lm_modl,lm_test)
  lm_rmse <- RMSE(lm_predic,lm_test$MonthlyIncome)
  lm_df <- rbind(lm_df,lm_rmse)
}
colnames(lm_df) <- c("RMSE")
lm_df
mean(lm_df$RMSE)
```

Both models are performing up to desired expectations.
Finally, we will use the fitted models to predict the given test sets.
```{r}

```

